# PBS 150 of X ‚Äî Bash: Script Plumbing

In [the previous instalment](./pbs149) we learned how to handle command line arguments with the same level of finesse typical terminal commands do, including with `-x` style named options. At this stage our scripts are almost first-class citizens of Terminal-land, they just need to learn one more trick ‚Äî to play nice with stream redirection, or as I like to call it, *Terminal plumbing* üôÇ

## Matching Podcast Episode

TO UPDATE

Listen along to this instalment on [episode 767 of the Chit Chat Across the Pond Podcast](https://www.podfeet.com/blog/2023/04/ccatp-767/).

<audio controls src="https://media.blubrry.com/nosillacast/traffic.libsyn.com/nosillacast/CCATP_2023_04_30.mp3?autoplay=0&loop=0&controls=1">Your browser does not support HTML 5 audio üôÅ</audio>

You can also <a href="https://media.blubrry.com/nosillacast/traffic.libsyn.com/nosillacast/CCATP_2023_04_30.mp3" >Download the MP3</a>

Read an unedited, auto-generated transcript:  <a href="https://podfeet.com/transcripts/CCATP_2023_04_30.html">CCATP_2023_04_30</a>

## Episode Resources

TO UPDATE

* The instalment ZIP file ‚Äî [pbs150.zip](https://github.com/bartificer/programming-by-stealth/raw/master/instalmentZips/pbs150.zip)


## PBS 149 Challenge Solution

The optional challenge at the end of [the previous instalment](./pbs149) was to update our  breakfast menu script so it accepts two options:

1. `-l LIMIT` where `LIMIT` is the maximum number of items that can be ordered, which must be a whole number greater than or equal to one.
2. `-s` to request some snark.

Here's my sample solution, which you'll find in the instalment ZIP as `pbs149-challengeSolution.sh`:

```bash
#!/usr/bin/env bash

# read the menu
declare -a menu
while read -r menuLine
do
    # skip comment lines
    echo "$menuLine" | egrep -q '^[ ]*#' && continue

    # skip empty lines
    echo "$menuLine" | egrep -q '^[ ]*$' && continue

    # store the menu item
    menu+=("$menuLine")
done <<<"$(cat $(dirname "$BASH_SOURCE")/menu.txt)"

# initialise the options to their default values
limit='' # no limit
snark='' # no snark

# Process the commandline options
while getopts ':l:s' opt
do
    case $opt in
        l)
            # validate and store the limit
            if echo "$OPTARG" | egrep '^[1-9][0-9]*$'
            then
                limit=$OPTARG
            else
                echo "invalid limit - must be an integer greater than zero"
                exit 2;
            fi
            ;;
        s)
            snark=1
            ;;
        ?)
            echo "Usage: $(basename $0) [-s] [-l LIMIT]"
            exit 2
    esac
done

# create an empty array to hold the order
declare -a order

# present the menu, with a done option
if [[ -z $limit ]]
then
    if [[ -n $snark ]]
    then
        echo "Wha' d' ya want (greed is grand)?"
    else
        echo 'Choose your breakfast (as many items as you like)'
    fi
else
    if [[ -n $snark ]]
    then
        echo "Pick no more than $limit things, and make it snappy!"
    else
        echo "Choose up to $limit breakfast items"
    fi
fi
select item in done "${menu[@]}"
do
    # skip invalid selections ($item is empty)
    [[ -z $item ]] && continue

    # exit if done
    [[ $item == done ]] && break

    # store and print the item
    order+=("$item")
    if [[ -n $snark ]]
    then
        echo "Fine, you can have $item"
    else
        echo "Added $item to your order"
    fi

    # if we're limiting, check the limit
    if [[ -n $limit ]]
    then
        [[ ${#order[@]} -ge $limit ]] && break
    fi
done

# print the order
if [[ -n $snark ]]
then
    echo -e "\nYour sodding ${#order[@]} items:"
else
    echo -e "\nYou ordered the following ${#order[@]} items:"
fi
for item in "${order[@]}"
do
    echo "* $item"
done
```

This solution is very much *by the book*, and there isn't really anything particularly worth highlighting other than noting that the section of the code that changed most is the section that processes the command line arguments:

```bash
# initialise the options to their default values
limit='' # no limit
snark='' # no snark

# Process the commandline options
while getopts ':l:s' opt
do
    case $opt in
        l)
            # validate and store the limit
            if echo "$OPTARG" | egrep '^[1-9][0-9]*$'
            then
                limit=$OPTARG
            else
                echo "invalid limit - must be an integer greater than zero"
                exit 2;
            fi
            ;;
        s)
            snark=1
            ;;
        ?)
            echo "Usage: $(basename $0) [-s] [-l LIMIT]"
            exit 2
    esac
done
```

This is a textbook example of using `getopts` for command line options. The first argument to `getopts` is the definition string, in this case `':l:s'`, and the second the name we choose to give to the variable that will hold the option name on each pass through the `while` loop. In terms of the variable name, I've stuck to the convention I recommended of always naming it `$opt`. Given how cryptic they appear, the definition string is worth a look. The leading `:` means we are taking responsibility for communicating error messages to the user, the `l:` means we support an optional argument named `l`, and the `s` means we support a flag named `s`. As a reminder, optional arguments are options that need values, and flags are those that do not.

## The POSIX Foundations of Stream Redirection in Bash

In this instalment we're going to focus on stream redirection from the point of view of a script author, not from the point of view of a terminal user. You'll find the user's point of view well covered in [Taming the Terminal](https://ttt.bartificer.net/) instalments [15](https://ttt.bartificer.net/book.html#ttt15) & [16](https://ttt.bartificer.net/book.html#ttt16).

It's important to note that the fundamental concepts we'll be building on today are not Bash specific, they're not even specific to shell scripts in general, but they are a fundamental part of the POSIX specification, and they're just as important to developers writing full-blown apps in compiled languages like C.

### Streams

In a POSIX-compliant OS, the operating system represents flows of data into, out of, and between processes as *streams*. The OS maintains a list of streams each process has access to, and presents those streams to those processes as numeric IDs, each process gets its own set of IDs, starting at zero. If a stream us used to connect one process to another, then it's more likely than not that each process will know the same stream by a different numeric ID.

From a process's point of view, each stream has a direction ‚Äî in other words, there are input streams, and output streams. If a stream is connecting two processes, then one process will see it as an output stream, while the other sees it as an input stream.

POSIX compliant OSes provides each process with three standard streams that always have the same numbering:

1. **Standard Input**, or `STDIN` which has the numeric ID `0` and is connected to the terminal session the process was started in by default. In other words, when a terminal window has focus, the keyboard is connected to the standard input stream of the process that's running running in that terminal.
2. **Standard Output**, or `STDOUT` which has the numeric ID `1` and is connected to the terminal window the process is running in by default.
3. **Standard Error**, or `STDERR` which has the numeric ID `2` and is also connected to the process's terminal window by default.

### File Descriptors

It probably comes as no surprise that under their hoods, POSIX-compliant OSes represent regular files as *file descriptors*. It probable doesn't come as much of a surprise that POSIX compliant OSes also use file descriptors to represent symbolic links (shortcuts from one file path to another) and directories (folders). What may surprise you is that POSIX uses file descriptors to represent just about everything that can send or receive data ‚Äî hardware devices are represented as file descriptors (usually in the special folder `/dev`), so are open network connections, and, most importantly for us, file descriptors can be used to represent streams.

The vast majority of files exist universally, that is to say, each process on the OS sees the same path as referring to the same thing, but there are some special paths that are process-specific. That is to say, each process gets their own copy of these file descriptors, pointing at different things.

The three best examples of process-specific file descriptors are:

1. `/dev/stdin` which represents the process's standard input stream.
2. `/dev/stdout` which represents the process's standard output stream.
3. `/dev/stderr` which represents the process's standard input stream.

Each file descriptor can take and/or provide data, or, to put it another way, each file descriptor is *readable* and/or *writeable*. For example, regular files can be written to or read from, but read-only files can only be read from. Similarly, a file descriptor representing a thumb drive can be read from or written to, but the file descriptor representing your keyboard and only be read from.

### Stream Redirection

The POSIX specification allows process to create streams, and to re-map them, so command shells like Bash shell can use the POSIX APIs to manipulate streams. It's these stream manipulations that I refer to as *terminal plumbing*.

## Stream Redirection in Bash

Bash provides a number of operators for manipulating streams. I won't go through them all, but the most important ones are listed below:

| Operator | Description | Example |
| :---: | :--- |
| `>` | Connects the output side of a stream to a writeable file descriptor. The stream ID goes to the left of the operator, and the file descriptor to the right. By default, the stream is assumed to be `STDOUT`, so you usually see the this operator used without a stream ID, but you do sometimes see it used to redirect `STDERR` to a file, so you will see the stream ID `2` quote often. | `wc -l </etc/hosts`, and `somescript.sh 2>error.log` |
| `<` | Connects a readable file descriptor to the input side of a stream. The stream ID goes to the left of the operator, and the file descriptor to the right. By default, the stream is assumed to be `STDIN`, so you almost always see the this operator used without a stream ID. | `wc -l </etc/hosts` |
| `|` | Used to chain processes together, the *pipe* connects the command to the left's `STDOUT` to the command to the right's `STDIN`. | `grep local /etc/hosts | wc -l` |

Bash also provides useful shortcut file descriptors for streams, `&n` where `n` is a number is a file descriptor for the stream with ID `n`, i.e. `STDIN` is `&0`, `STDOUT` is `&1`, and `STDERR` is `&2`.

This makes it possible to use the `>` operator to merge two output streams into one, e.g. to merge `STDERR` into `STDOUT` you need to send the stream with ID `2` to the file descriptor for the stream with ID `1`, i.e. `2>&1`.

LEFT OFF HERE






### Redirecting a File Into a Script

If you use the `<` operator to send the contents of a file to `STDIN` when calling a shell script, then any time the shell script tries to read from `STDIN`, it reads from the file rather than waiting for keyboard input.

We can see this in action by redirecting the contents of the text file `favouriteOrder.txt` in the instalment ZIP to `STDIN` when calling the sample solution to the previous instalment (also in the ZIP). Before we call the script, let's have a look at the contents of the file:

```text
2
3
1
```

You'll notice that corresponds to the menu options *pancakes*, *waffles*, and *done*.

Let's now run our script with the contents of this text file as the standard input:

```bash
./pbs149-challengeSolution.sh <favouriteOrder.txt
```

What you'll see is that the script behaves as if we had typed `2` the first time we were offered the menu, then `3` the second time, and finally `1` the third time, i.e. we order pancakes, waffles, and then finish our order.

### Redirecting the Output of a Script to a File

We can update the command above to send the outputs from our script to a file by redirecting `STDOUT` to a text file name `transcript.txt` with:

```bash
./pbs149-challengeSolution.sh <favouriteOrder.txt >transcript.txt
```

The first thing you'll notice is that the terminal is not showing most of the output. This is because `STDOUT` was redirected from the terminal to the file, so let's see what's in the file (`cat transcript.txt`):

```text
Choose your breakfast (as many items as you like)
Added pancakes to your order
Added waffles to your order


You ordered the following 2 items:
* pancakes
* waffles
```

Notice that some output still went to the terminal ‚Äî specifically that outputted by the `select` loop. Also notice that any output that went to the terminal didn't go into the file. Why is that? 

The reason for this behaviour is that the output that still went to the terminal was not written to `STDOUT`, but instead, it was written to standard error (`STDERR`). By default both go to the terminal, but the `>` operator only redirects `STDOUT`, so the two streams are now separated.

## Using Streams in Your Scripts

This is the perfect opportunity to switch modes and start tweaking our scripts to make better use of the streams the redirection operators control.

### Writing to `STDERR` rather than `STDOUT`

As things stand, our prompt asking for items is going to `STDOUT`, but our menu is going to `STDERR`, ideally, we should update the script to send the prompt text to the `STDERR` too. We can do that by redirecting `STDOUT` (stream `1`) to `STDERR` (stream `2`) on each echo command we want to exclude from the standard output by appending the command with the redirection `1>&2` , e.g.:

```bash
echo 'Choose your breakfast (as many items as you like)' 1>&2
```

You'll find a version of the script with all appropriate `echo` commands redirected to `STDERR` in the file `pbs150a-menu.sh` in the instalment ZIP.

We can run our favourite order through this updated script with:

```bash
./pbs150a-menu.sh <favouriteOrder.txt >transcript.txt
```

And now we get a more useful transcript:

```text
Added pancakes to your order
Added waffles to your order


You ordered the following 2 items:
* pancakes
* waffles
```

Better yet, we can use the command interactively, even when capturing the output in the transcript file. Try it with:

```bash
./pbs150a-menu.sh >transcript.txt
```

So, **think carefully about what output your script sends to `STDOUT`, and what output it sends to `STDERR`**.

### Scripts in Piplelines

We can send the output from another command into our script as the standard input using the `|`, e.g.:

```bash
echo -e "2\n3\n1" | ./pbs150a-menu.sh
```

We can of course then go on to redirect the output from our script to another script or terminal command by adding another pipe, in this case, we can count the lines the script write to standard out with:

```bash
echo -e "2\n3\n1" | ./pbs150a-menu.sh | wc -l
```

You'll see the answer is `6`, but the output to `STDERR` coming from our script is confusing things, so let's hide the output to `STDERR` by redirecting it (stream `2`) to the null device (`/dev/null`), a kind of data black hole in all Linux/Unix systems:

```bash
echo -e "2\n3\n1" | ./pbs150a-menu.sh 2>/dev/null | wc -l
```

Now our line count is much clearer!

### Streams are Inherited

When your script calls another terminal command, that terminal command inherits the three standard streams (`STDIN`, `STDOUT` & `STDERR`). This means that all commands you call that write to `STDOUT` go to where ever your script is outputting, and, any command you call that tries to read from `STDIN` will read from where ever your script is getting it standard input.

This is why the `read` and `select in` commands in our sample solution worked when we redirected our text file to the script's input stream.

### Reading `STDIN` is Destructive

When you read a character from the standard input stream it's gone from the standard input stream! 

This means that to use the standard input stream's contents in our scripts, we often need to capture and store it. What's more, we should do that early in our script, because every other command we call from our script has the ability to read, and hence destroy, any data in the standard input stream!

### Capturing `STDIN`

We've already seen that the `read` command takes its information from `STDIN`, but it does so in pieces, not all at once. By default, it does so line-by-line, but what's really going on is that it does so `$IFS` by `$IFS`. What `read` does is copy characters from `STDIN` to a variable character-by-character until it meets a character equal to the *input fields separator*, i.e. the POSIX variable `$IFS`. This means you can use use `read` to slurp in all the data in `STDIN` by setting `$IFS` to an empty string. I'm not a fan of this approach because it means I have to remember to be sure I make my change to `$IFS` in such a way that I avoid *'spooky action at a distance'* bugs.

My preferred method for reading all of `STDIN` into a variable at once, known colloquially as *slurping* the standard input, is to use the `cat` command with no arguments. As its `man` page says, when passed no arguments is writes `STDIN` to `STDOUT`. Because `cat` will inherit our script's `STDIN` it will read what we want it to read, and we can then use the `$()` syntax to store the command's output in a variable.

We. can see this in action with the simple script `pbs150b-naiveShouter.sh` in the instalment ZIP:

```bash
#!/usr/bin/env bash

# always read STDIN into a variable
theInput=$(cat)

# convert the input to all upper case with the tr command
theOutput=$(echo "$theInput" | tr [:lower:] [:upper:])

# output the upper-cased text
echo "$theOutput"
```

This script slurps all of STDIN, converts it to upper case using [the `tr` (*translate*) command](https://www.baeldung.com/linux/tr-command), then outputs the upper-case, i.e. *shouty* text to `STDOUT`.

Notice how we read the input into `$theInput` with the simple line:

```bash
theInput=$(cat)
```

We can see this script in action with the command:

```bash
echo 'hello world!' | ./pbs150b-naiveShouter.sh
```

But what happens if we try to run this script without redirecting a finite piece of text to `STDIN`? The script will hang, waiting for input from the keyboard, and because we are using `cat` rather than `read`, it will keep accepting the input even after we hit return. In fact, it will keep waiting for input until we enter the EOF (End of File) character, which we can type with `ctrl+d`. Try it:

```bash
./pbs150b-naiveShouter.sh
```

### Intelligently Slurping `STDIN`

That's clearly sub-optimal, so the obvious question you're probably asking is *'how do we detect whether or not `STDIN` has content for us to slurp?'*.

I'm sorry to say, if you need your script to be portable, and to work everywhere, you can't üôÅ

If you know your script will always be run with modern versions of Bash, i.e. never on a Mac, then you can use the exit code from `read -t 0` to detect whether or not there is data to be read in `STDIN`, but alas that does not work in older versions of Bash, like the one Apple still ship in even the very latest macOS versions.

That does not mean we can't write user-friendly scripts ‚Äî we can simply copy the behaviour of standard terminal commands like `cat` and `grep`.

Both of these commands are examples of a common convention used by most terminal commands that need a stream of input to work on.

They implement a simple two-rule algorithm:

1. If zero files are specified, read from STDIN
2. If one or more files are specified, check each file path to see if it is `-`, if it is, read from `STDIN`, otherwise, read from the file

Because this is a very common convention, `getopts` does not get confused by the lone `-` used to represent `STDIN`.

To see this in action, let's update our shouting script to implement the `cat` convention, and, to support an optional `-b` flag to request an exclamation point (a *bang*) be appended to the output.

You'll find this script in the instalment ZIP as `pbs150c-shouter.sh`:

```bash
#!/usr/bin/env bash

# start by processing the options
bang='' # assume no bang
while getopts ":b" opt
do
    case $opt in
        b)
            bang='!'
            ;;
        ?)
            echo "Usage: $(basename $0) [-b] [FILE|-]..."
            exit 2
            ;;
    esac
done
shift $(echo "$OPTIND-1" | bc)

#
# -- load the text to shout --
#
text=''

# if there are no args, read STDIN
if [[ $# = 0 ]]
then
    text+=$(cat)
fi

# loop over all args and read from files or STDIN as appropriate
for path in "$@"
do
    # determine whether to treat as file or STDIN
    if [[ $path = '-' ]]
    then
        # read from STDIN
        text+=$(cat)
    else
        # read from file
        text+=$(cat "$path")
    fi
done

# convert the text to all upper case with the tr command
shoutedText=$(echo "$text" | tr [:lower:] [:upper:])

# output the upper-cased text and its optional bang
echo "$shoutedText$bang"
```

We can now see this script behave like `cat` with the following examples:

```bash
# no args means assume STDIN
echo 'hello world' | ./pbs150c-shouter.sh
echo 'hello world' | ./pbs150c-shouter.sh -b

# regular file args are read as files
./pbs150c-shouter.sh menu.txt
./pbs150c-shouter.sh -b menu.txt

# the - can be added to the file list to read STDIN and regular files
echo -e "\n\nhello world" | ./pbs150c-shouter.sh -b menu.txt -
```

## Final Thoughts

We're nearing the end of our Bash journey now ‚Äî we can write shell scripts that behave just like standard terminal commands. They can play nice in the pipeline, they can accept options in the traditional way, and they'll run reliably on a very broad range of OSes.

What's left to do? Mostly, just a little housekeeping!

I want to finish the series by making some things we've been doing implicitly explicit, specifically the different kinds of expansions Bash can do, and the exact behaviour of the various kinds of brackets that can be used to group things.

But, before doing that, I want to look at controlling scope in a little more detail, and, at better output formatting with `printf` rather than `echo`. That's where we'll start next time.

### An Optional Challenge

_**NOTE (May 2023):** this challenge can only be partially completed without an understanding of `/dev/tty`, which I did not realise when I set the challenge. It will be covered in the next instalment, and this note will be replaced with a link to the relevant information once the next instalment is out. I guess you could say the class has an extension on their assignment üôÇ_ 

Update your challenge solution from last time so it can optionally load the menu from a or from `STDIN`. Add an option named `-m` (for *menu*), and if that option has the value `-`, read from `STDIN`, otherwise, treat the value of `-m` as a file path and load the menu from that file. If `-m` is not passed, default to reading from `./menu.txt`.

Also, make a conscious choice about what goes to `STDOUT` and `STDERR`.